{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c7cccf",
   "metadata": {},
   "source": [
    "# [M_01] PROTOK√ì≈Å: ANALIZA MULTIMODALNA (GEMINI 3 FLASH)\n",
    "\n",
    "**PROJEKT:** OMNI-OPERATOR-V1  \n",
    "**ORGANIZACJA:** [KU≈πNIA OPERATOR√ìW](https://takzenai-hub.pl)  \n",
    "**STATUS:** OPERACJA_WIDZENIA\n",
    "\n",
    "Ten modu≈Ç implementuje logikƒô multimodalnej analizy surowego materia≈Çu wideo. Wykorzystujemy model **Gemini 3 Flash**, aby bezpo≈õrednio wyekstrahowaƒá kluczowe momenty (hooki) oraz strukturƒô narracyjnƒÖ. \n",
    "\n",
    "**Dlaczego to jest prze≈Çomowe?**\n",
    "1. **Brak transkrypcji:** Nie tracimy czasu na Whisper/STT. Gemini widzi gesty, emocje i tekst na ekranie.\n",
    "2. **Video Grounding:** Model ≈ÇƒÖczy d≈∫wiƒôk z konkretnymi klatkami obrazu.\n",
    "3. **Structured Outputs:** Wynik trafia bezpo≈õrednio do modelu Pydantic, gotowy do automatycznego monta≈ºu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc01b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: System analityczny gotowy. Katalog ROOT: c:\\Users\\takze\\OneDrive\\Pulpit\\project\\omni-operator-v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from google import genai  \n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# 1. KOREKTA ≈öCIE≈ªKI ROBOCZEJ\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# Dodanie src do path, aby widzieƒá modu≈Ç core\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "\n",
    "from src.core.config import settings\n",
    "\n",
    "# 2. KONFIGURACJA SILNIKA\n",
    "client = genai.Client(api_key=settings.gemini_api_key)  \n",
    "\n",
    "print(f\"LOG: System analityczny gotowy. Katalog ROOT: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8aeba",
   "metadata": {},
   "source": [
    "## 1. Definicja Kontraktu Danych (Structured Output)\n",
    "\n",
    "Ustalenie ≈õcis≈Çego schematu jest kluczowe dla Etapu 3 (Monta≈º FFmpeg). Gemini musi zwr√≥ciƒá dane w formacie, kt√≥ry Python zrozumie bezb≈Çƒôdnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5bdec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Modele danych Pydantic zainicjalizowane.\n"
     ]
    }
   ],
   "source": [
    "class ShotCandidate(BaseModel):\n",
    "    \"\"\"Reprezentuje fragment wideo wyselekcjonowany pod kƒÖtem viralowym.\"\"\"\n",
    "    start: str = Field(description=\"Znacznik czasu rozpoczƒôcia fragmentu (format MM:SS)\")\n",
    "    end: str = Field(description=\"Znacznik czasu zako≈Ñczenia fragmentu (format MM:SS)\")\n",
    "    visual_description: str = Field(description=\"Opis tego, co dzieje siƒô na obrazie w tym momencie\")\n",
    "    narrative_hook: str = Field(description=\"Dlaczego ten moment przyciƒÖgnie uwagƒô widza\")\n",
    "    score: int = Field(description=\"Potencja≈Ç viralowy w skali 1-10\")\n",
    "\n",
    "class VideoAnalysisReport(BaseModel):\n",
    "    \"\"\"Kompletny raport z analizy materia≈Çu ≈∫r√≥d≈Çowego.\"\"\"\n",
    "    main_topic: str = Field(description=\"G≈Ç√≥wny temat i cel nagrania\")\n",
    "    suggested_titles: List[str] = Field(description=\"Propozycje chwytliwych tytu≈Ç√≥w (max 3)\")\n",
    "    clips: List[ShotCandidate] = Field(description=\"Lista sugerowanych fragment√≥w do wyciƒôcia\")\n",
    "\n",
    "print(\"LOG: Modele danych Pydantic zainicjalizowane.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ea6e6",
   "metadata": {},
   "source": [
    "## 2. ZarzƒÖdzanie Plikami Medi√≥w (Google File API)\n",
    "\n",
    "Przed analizƒÖ plik wideo musi zostaƒá zaindeksowany przez Google. Gemini 3 Flash wymaga, aby plik posiada≈Ç status `ACTIVE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1defd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gemini(file_path: str):\n",
    "    \"\"\"Przesy≈Ça plik do API i monitoruje status przetwarzania.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"B≈ÇƒÖd: Nie znaleziono pliku {file_path} w katalogu ROOT.\")\n",
    "\n",
    "    print(f\"LOG: Przesy≈Çanie materia≈Çu {file_path} do Google Cloud...\")\n",
    "    media_file = genai.upload_file(path=file_path)\n",
    "    \n",
    "    # Czekanie na przetworzenie przez serwery Google\n",
    "    while media_file.state.name == \"PROCESSING\":\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(3)\n",
    "        media_file = genai.get_file(media_file.name)\n",
    "        \n",
    "    if media_file.state.name == \"FAILED\":\n",
    "        raise RuntimeError(\"LOG: Przetwarzanie wideo przez Google API zako≈Ñczone niepowodzeniem.\")\n",
    "        \n",
    "    print(f\"\\nLOG: Materia≈Ç aktywny. URI: {media_file.uri}\")\n",
    "    return media_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae0d18",
   "metadata": {},
   "source": [
    "## 3. Wykonanie Analizy (Native Vision & Reasoning)\n",
    "\n",
    "Uruchamiamy proces analizy. U≈ºywamy mechanizmu `response_schema`, aby wymusiƒá na modelu Gemini 2.5 Flash ≈õcis≈Çe trzymanie siƒô naszej struktury danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0e1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Przesy≈Çanie materia≈Çu test_video.mp4 do Google Cloud...\n",
      "‚ùå B≈ÅƒÑD OPERACYJNY: module 'google.genai' has no attribute 'upload_file'\n"
     ]
    }
   ],
   "source": [
    "# KRYTYCZNE: Upewnij siƒô, ≈ºe plik test_video.mp4 jest w Twoim folderze g≈Ç√≥wnym!\n",
    "INPUT_FILE = \"test_video.mp4\"\n",
    "\n",
    "async def run_multimodal_analysis():\n",
    "    try:\n",
    "        # 1. Upload medi√≥w\n",
    "        video_handle = upload_to_gemini(INPUT_FILE)\n",
    "        \n",
    "        # 2. Inicjalizacja modelu\n",
    "        model = genai.GenerativeModel(model_name=\"gemini-3-flash-preview\") # Zgodnie z API, 2.5 jest dostƒôpne jako 2.5-flash-latest lub exp\n",
    "        \n",
    "        prompt = (\n",
    "            \"Przeanalizuj to nagranie wideo pod kƒÖtem tworzenia kr√≥tkich tre≈õci (Shorts/TikTok). \"\n",
    "            \"Zidentyfikuj g≈Ç√≥wny temat i wybierz 3 momenty o najwy≈ºszym potencjale viralowym. \"\n",
    "            \"Zwr√≥ƒá wynik jako czysty JSON zgodny ze strukturƒÖ VideoAnalysisReport.\"\n",
    "        )\n",
    "        \n",
    "        # 3. Analiza z wymuszeniem schematu\n",
    "        print(\"LOG: Agent analizuje obraz i d≈∫wiƒôk...\")\n",
    "        response = model.generate_content(\n",
    "            [prompt, video_handle],\n",
    "            generation_config={\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_schema\": VideoAnalysisReport\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 4. Parsowanie i walidacja\n",
    "        report_data = json.loads(response.text)\n",
    "        report = VideoAnalysisReport.model_validate(report_data)\n",
    "        \n",
    "        # 5. Prezentacja wynik√≥w\n",
    "        print(\"\\n\" + \"=\"*45)\n",
    "        print(f\"üöÄ RAPORT: {report.main_topic.upper()}\")\n",
    "        print(\"=\"*45)\n",
    "        for i, clip in enumerate(report.clips, 1):\n",
    "            print(f\"CLIP {i}: [{clip.start} - {clip.end}] (Score: {clip.score}/10)\")\n",
    "            print(f\"VISUAL: {clip.visual_description}\")\n",
    "            print(f\"HOOK: {clip.narrative_hook}\\n\")\n",
    "            \n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå B≈ÅƒÑD OPERACYJNY: {str(e)}\")\n",
    "\n",
    "# URUCHOMIENIE\n",
    "analysis_result = await run_multimodal_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963544d",
   "metadata": {},
   "source": [
    "## STATUS: MODU≈Å 01 ZAKO≈ÉCZONY\n",
    "\n",
    "Mamy gotowe dane wej≈õciowe do monta≈ºu. System \"zrozumia≈Ç\" wideo i wytypowa≈Ç momenty do wyciƒôcia.\n",
    "\n",
    "**Kolejne kroki:**\n",
    "1. Zapisz notatnik.\n",
    "2. Przejd≈∫ do `notebooks/02_AGENT_COPYWRITER.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omni-operator-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
