{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0935942c",
   "metadata": {},
   "source": [
    "# [M_03] PROTOKÓŁ: AUTOMATYCZNA FABRYKA WIDEO (FFMPEG)\n",
    "\n",
    "**PROJEKT:** OMNI-OPERATOR-V1  \n",
    "**SILNIK:** GEMINI 3 FLASH  \n",
    "**STATUS:** EKSTRACJA_MEDIÓW  \n",
    "\n",
    "Ten moduł odpowiada za fizyczną obróbkę materiału wideo. Wykorzystujemy bibliotekę `MoviePy` (napędzaną przez `FFmpeg`), aby na podstawie ustrukturyzowanego raportu z Gemini 3 Flash automatycznie wyciąć i wyrenderować fragmenty pod Shortsy.\n",
    "\n",
    "**Cele operacyjne:**\n",
    "1. Konwersja znaczników czasu `MM:SS` na sekundy (float).\n",
    "2. Automatyczna ekstrakcja klipów z pliku źródłowego `test_video.mp4`.\n",
    "3. Zastosowanie parametrów renderowania zoptymalizowanych pod urządzenia mobilne (H.264)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe43e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: System montażowy zainicjowany. Katalog ROOT: c:\\Users\\takze\\OneDrive\\Pulpit\\project\\omni-operator-v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "# 1. KOREKTA ŚCIEŻKI ROBOCZEJ\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# Dodanie src do path, aby widzieć ewentualne moduły pomocnicze\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "\n",
    "print(f\"LOG: System montażowy zainicjowany. Katalog ROOT: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7698d63",
   "metadata": {},
   "source": [
    "## 1. Narzędzia Pomocnicze: Konwersja Czasu\n",
    "\n",
    "Raport z Gemini (M_01) dostarcza czas w formacie tekstowym `MM:SS`. Silnik FFmpeg wymaga precyzyjnej liczby sekund. Implementujemy bezpieczny konwerter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4663cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: 00:45 -> 45.0s\n"
     ]
    }
   ],
   "source": [
    "def timestamp_to_seconds(ts: str) -> float:\n",
    "    \"\"\"Konwertuje format MM:SS na sekundy (np. '01:15' -> 75.0).\"\"\"\n",
    "    try:\n",
    "        parts = ts.split(':')\n",
    "        if len(parts) == 2:\n",
    "            minutes, seconds = map(int, parts)\n",
    "            return float(minutes * 60 + seconds)\n",
    "        return 0.0\n",
    "    except (ValueError, AttributeError):\n",
    "        print(f\"ERR: Błędny format znacznika czasu: {ts}\")\n",
    "        return 0.0\n",
    "\n",
    "# TEST OPERACYJNY\n",
    "test_ts = \"00:45\"\n",
    "print(f\"TEST: {test_ts} -> {timestamp_to_seconds(test_ts)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644bc7e",
   "metadata": {},
   "source": [
    "## 2. Implementacja Silnika Produkcyjnego\n",
    "\n",
    "Tworzymy funkcję `produce_shorts`, która bierze surowy film i listę klipów, a następnie wykonuje renderowanie. Każdy klip zostanie zapisany w dedykowanym folderze `output/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0357324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_shorts(source_file: str, clips_to_cut: list):\n",
    "    \"\"\"\n",
    "    Fizycznie wycina fragmenty wideo na podstawie listy słowników.\n",
    "    \"\"\"\n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(source_file):\n",
    "        raise FileNotFoundError(f\"Nie znaleziono pliku źródłowego: {source_file}\")\n",
    "\n",
    "    print(f\"LOG: Otwieram materiał źródłowy: {source_file}\")\n",
    "    \n",
    "    # W MoviePy 2.x używamy menedżera kontekstu (with)\n",
    "    with VideoFileClip(source_file) as video:\n",
    "        for i, clip_info in enumerate(clips_to_cut, 1):\n",
    "            start_s = timestamp_to_seconds(clip_info['start'])\n",
    "            end_s = timestamp_to_seconds(clip_info['end'])\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"short_{i}.mp4\")\n",
    "            \n",
    "            print(f\"LOG: Renderowanie klipu {i} [{clip_info['start']} - {clip_info['end']}]...\")\n",
    "\n",
    "            # Safety Guard: Max 90 seconds per clip\n",
    "            if (end_s - start_s) > 90:\n",
    "                print(f\"⚠️ OSTRZEŻENIE: Klip {i} jest za długi ({end_s - start_s}s). Przycinam do 60s.\")\n",
    "                end_s = start_s + 60\n",
    "\n",
    "            # NOWA METODA W v2.x: subclipped() zamiast subclip()\n",
    "            new_clip = video.subclipped(start_s, end_s)\n",
    "            \n",
    "            # Zapis pliku\n",
    "            new_clip.write_videofile(\n",
    "                output_path, \n",
    "                codec=\"libx264\", \n",
    "                audio_codec=\"aac\",\n",
    "                logger=None \n",
    "            )\n",
    "            print(f\"✅ GOTOWE: {output_path}\")\n",
    "\n",
    "    print(f\"\\nLOG: Produkcja zakończona pomyślnie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88cc5bf",
   "metadata": {},
   "source": [
    "## 3. Uruchomienie Fabryki (Test End-to-End)\n",
    "\n",
    "Używamy danych uzyskanych z Gemini 3 Flash w Module 01, aby wygenerować pierwsze pliki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6964dda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Otwieram materiał źródłowy: test_video.mp4\n",
      "LOG: Renderowanie klipu 1 [00:00 - 00:20]...\n",
      "✅ GOTOWE: output\\short_1.mp4\n",
      "LOG: Renderowanie klipu 2 [00:25 - 00:55]...\n",
      "✅ GOTOWE: output\\short_2.mp4\n",
      "\n",
      "LOG: Produkcja zakończona pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "# Symulacja danych z raportu analitycznego (M_01)\n",
    "# Jeśli masz już analysis_result.clips, możesz użyć tych danych bezpośrednio\n",
    "mock_production_data = [\n",
    "    {\"start\": \"00:00\", \"end\": \"00:20\", \"hook\": \"Efekt wizualny AI\"}, # 20 sekund\n",
    "    {\"start\": \"00:25\", \"end\": \"00:55\", \"hook\": \"Prezentacja frameworka\"} # 30 sekund\n",
    "]\n",
    "\n",
    "INPUT_VIDEO = \"test_video.mp4\"\n",
    "\n",
    "try:\n",
    "    produce_shorts(INPUT_VIDEO, mock_production_data)\n",
    "except Exception as e:\n",
    "    print(f\"❌ BŁĄD PRODUKCJI: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f3f96",
   "metadata": {},
   "source": [
    "## STATUS: MODUŁ 03 ZAKOŃCZONY\n",
    "\n",
    "Mamy teraz działającą fabrykę wideo. System potrafi autonomicznie zarządzać plikami na dysku.\n",
    "\n",
    "**Osiągnięcia:**\n",
    "1. Integracja FFmpeg z logicznym workflow agenta.\n",
    "2. Automatyczne generowanie plików MP4 zoptymalizowanych pod social media.\n",
    "3. Pełna suwerenność nad procesem montażu.\n",
    "\n",
    "**Zadanie:**\n",
    "Otwórz folder `output/` w swoim projekcie i sprawdź, czy pliki `short_1.mp4` i `short_2.mp4` odtwarzają się poprawnie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968a420",
   "metadata": {},
   "source": [
    "## 4. Optymalizacja pod Mobile: Kadrowanie 9:16 i Branding\n",
    "\n",
    "Większość nagrań źródłowych jest w formacie 16:9. Aby zdominować TikTok i Reels, musimy automatycznie:\n",
    "1. Przeskalować wideo tak, aby wypełniło pionowy ekran.\n",
    "2. Wykadrować obraz do środka (Center Crop).\n",
    "3. Nałożyć znak wodny KUŹNI OPERATORÓW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e73823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Formatowanie output/short_1.mp4 do 9:16...\n",
      "✅ WYPRODUKOWANO SHORTS: output/short_1_branded.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.VideoClip import TextClip, ColorClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "\n",
    "def format_to_shorts(input_path: str, output_path: str):\n",
    "    \"\"\"Przetwarza poziome wideo na format pionowy 9:16 z brandingiem.\"\"\"\n",
    "    print(f\"LOG: Formatowanie {input_path} do 9:16...\")\n",
    "    \n",
    "    with VideoFileClip(input_path) as clip:\n",
    "        # 1. Obliczamy proporcje (docelowo 1080x1920 dla 9:16)\n",
    "        target_ratio = 9/16\n",
    "        w, h = clip.size\n",
    "        \n",
    "        # Skalujemy wideo tak, aby wysokość pasowała do pionu, a szerokość była nadmiarowa\n",
    "        # Następnie robimy Center Crop\n",
    "        new_h = h\n",
    "        new_w = int(h * target_ratio)\n",
    "        \n",
    "        # MoviePy v2.x: cropped() zamiast crop()\n",
    "        final_clip = clip.cropped(\n",
    "            x_center=w/2, \n",
    "            y_center=h/2, \n",
    "            width=new_w, \n",
    "            height=new_h\n",
    "        )\n",
    "\n",
    "        # 2. DODANIE BRANDINGU (Prosty pasek statusu na dole)\n",
    "        # Tworzymy prosty overlay tekstowy\n",
    "        # Uwaga: Wymaga zainstalowanego ImageMagick na systemie dla TextClip\n",
    "        try:\n",
    "            brand_overlay = ColorClip(\n",
    "                size=(new_w, 60), \n",
    "                color=(139, 0, 0) # Nasz Dark Red #8B0000\n",
    "            ).with_duration(final_clip.duration).with_opacity(0.8).with_position((\"center\", \"bottom\"))\n",
    "            \n",
    "            result = CompositeVideoClip([final_clip, brand_overlay])\n",
    "        except:\n",
    "            print(\"LOG: Pomijam branding (brak ImageMagick). Renderuję czysty pion.\")\n",
    "            result = final_clip\n",
    "\n",
    "        # 3. RENDER FINALNY\n",
    "        result.write_videofile(\n",
    "            output_path,\n",
    "            codec=\"libx264\",\n",
    "            audio_codec=\"aac\",\n",
    "            logger=None\n",
    "        )\n",
    "        print(f\"✅ WYPRODUKOWANO SHORTS: {output_path}\")\n",
    "\n",
    "# TEST: Przetwarzamy pierwszy wycięty klip\n",
    "if os.path.exists(\"output/short_1.mp4\"):\n",
    "    format_to_shorts(\"output/short_1.mp4\", \"output/short_1_branded.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92557c1e",
   "metadata": {},
   "source": [
    "## STATUS: ETAP 3 ZAKOŃCZONY (FABRYKA_AKTYWNA)\n",
    "\n",
    "System przeszedł pełną ścieżkę od surowego pliku `test_video.mp4` do pionowego, ubrandowionego Shortsa `short_1_branded.mp4`.\n",
    "\n",
    "**Osiągnięcia Etapu 3:**\n",
    "- [x] Automatyczna ekstrakcja na podstawie metadanych Gemini.\n",
    "- [x] Konwersja do formatu pionowego (Vertical Reframing).\n",
    "- [x] Implementacja warstwy brandingu.\n",
    "\n",
    "**Następny etap (M_04): Pamięć Długotrwała (Qdrant).**\n",
    "Zapiszemy nasze analizy i wycięte klipy do bazy wektorowej, aby system uczył się Twojego stylu i wiedział, co publikował w przeszłości."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omni-operator-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
