{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0935942c",
   "metadata": {},
   "source": [
    "# [M_03] PROTOCOL: AUTOMATIC VIDEO FACTORY (FFMPEG)\n",
    "\n",
    "**PROJECT:** OMNI-OPERATOR-V1  \n",
    "**ENGINE:** GEMINI 3 FLASH  \n",
    "**STATUS:** MEDIA_EXTRACTION  \n",
    "\n",
    "This module is responsible for physical video material processing. We use the `MoviePy` library (powered by `FFmpeg`) to automatically cut and render fragments for Shorts based on structured report from Gemini 3 Flash.\n",
    "\n",
    "**Operational objectives:**\n",
    "1. Converting `MM:SS` timestamps to seconds (float).\n",
    "2. Automatic clip extraction from source file `test_video.mp4`.\n",
    "3. Applying rendering parameters optimized for mobile devices (H.264)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe43e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Editing system initialized. ROOT directory: c:\\Users\\takze\\OneDrive\\Pulpit\\project\\omni-operator-v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "# 1. WORKING DIRECTORY CORRECTION\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# Adding src to path to see potential helper modules\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "\n",
    "print(f\"LOG: Editing system initialized. ROOT directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7698d63",
   "metadata": {},
   "source": [
    "## 1. Helper Tools: Time Conversion\n",
    "\n",
    "The report from Gemini (M_01) provides time in text format `MM:SS`. FFmpeg engine requires precise number of seconds. We implement safe converter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4663cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: 00:45 -> 45.0s\n"
     ]
    }
   ],
   "source": [
    "def timestamp_to_seconds(ts: str) -> float:\n",
    "    \"\"\"Converts MM:SS format to seconds (e.g. '01:15' -> 75.0).\"\"\"\n",
    "    try:\n",
    "        parts = ts.split(':')\n",
    "        if len(parts) == 2:\n",
    "            minutes, seconds = map(int, parts)\n",
    "            return float(minutes * 60 + seconds)\n",
    "        return 0.0\n",
    "    except (ValueError, AttributeError):\n",
    "        print(f\"ERR: Invalid timestamp format: {ts}\")\n",
    "        return 0.0\n",
    "\n",
    "# OPERATIONAL TEST\n",
    "test_ts = \"00:45\"\n",
    "print(f\"TEST: {test_ts} -> {timestamp_to_seconds(test_ts)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644bc7e",
   "metadata": {},
   "source": [
    "## 2. Production Engine Implementation\n",
    "\n",
    "We create `produce_shorts` function that takes raw video and list of clips, then performs rendering. Each clip will be saved in dedicated `output/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0357324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_shorts(source_file: str, clips_to_cut: list):\n",
    "    \"\"\"\n",
    "    Physically cuts video fragments based on list of dictionaries.\n",
    "    \"\"\"\n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(source_file):\n",
    "        raise FileNotFoundError(f\"Source file not found: {source_file}\")\n",
    "\n",
    "    print(f\"LOG: Opening source material: {source_file}\")\n",
    "    \n",
    "    # In MoviePy 2.x we use context manager (with)\n",
    "    with VideoFileClip(source_file) as video:\n",
    "        for i, clip_info in enumerate(clips_to_cut, 1):\n",
    "            start_s = timestamp_to_seconds(clip_info['start'])\n",
    "            end_s = timestamp_to_seconds(clip_info['end'])\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"short_{i}.mp4\")\n",
    "            \n",
    "            print(f\"LOG: Rendering clip {i} [{clip_info['start']} - {clip_info['end']}]...\")\n",
    "\n",
    "            # Safety Guard: Max 90 seconds per clip\n",
    "            if (end_s - start_s) > 90:\n",
    "                print(f\"⚠️ WARNING: Clip {i} is too long ({end_s - start_s}s). Trimming to 60s.\")\n",
    "                end_s = start_s + 60\n",
    "\n",
    "            # NEW METHOD IN v2.x: subclipped() instead of subclip()\n",
    "            new_clip = video.subclipped(start_s, end_s)\n",
    "            \n",
    "            # File save\n",
    "            new_clip.write_videofile(\n",
    "                output_path, \n",
    "                codec=\"libx264\", \n",
    "                audio_codec=\"aac\",\n",
    "                logger=None \n",
    "            )\n",
    "            print(f\"✅ READY: {output_path}\")\n",
    "\n",
    "    print(f\"\\nLOG: Production completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88cc5bf",
   "metadata": {},
   "source": [
    "## 3. Factory Launch (End-to-End Test)\n",
    "\n",
    "We use data obtained from Gemini 3 Flash in Module 01 to generate first files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6964dda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Opening source material: test_video.mp4\n",
      "LOG: Rendering clip 1 [00:00 - 00:20]...\n",
      "✅ READY: output\\short_1.mp4\n",
      "LOG: Rendering clip 2 [00:25 - 00:55]...\n",
      "✅ READY: output\\short_2.mp4\n",
      "\n",
      "LOG: Production completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Simulation of data from analytical report (M_01)\n",
    "# If you already have analysis_result.clips, you can use that data directly\n",
    "mock_production_data = [\n",
    "    {\"start\": \"00:00\", \"end\": \"00:20\", \"hook\": \"AI visual effect\"}, # 20 seconds\n",
    "    {\"start\": \"00:25\", \"end\": \"00:55\", \"hook\": \"Framework presentation\"} # 30 seconds\n",
    "]\n",
    "\n",
    "INPUT_VIDEO = \"test_video.mp4\"\n",
    "\n",
    "try:\n",
    "    produce_shorts(INPUT_VIDEO, mock_production_data)\n",
    "except Exception as e:\n",
    "    print(f\"❌ PRODUCTION ERROR: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f3f96",
   "metadata": {},
   "source": [
    "## STATUS: MODULE 03 COMPLETED 70%\n",
    "\n",
    "We now have a working video factory. The system can autonomously manage files on disk.\n",
    "\n",
    "**Achievements:**\n",
    "1. FFmpeg integration with logical agent workflow.\n",
    "2. Automatic generation of MP4 files optimized for social media.\n",
    "3. Full sovereignty over editing process.\n",
    "\n",
    "**Task:**\n",
    "Open `output/` folder in your project and check if `short_1.mp4` and `short_2.mp4` files play correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968a420",
   "metadata": {},
   "source": [
    "## 4. Mobile Optimization: 9:16 Framing and Branding\n",
    "\n",
    "Most source recordings are in 16:9 format. To dominate TikTok and Reels, we must automatically:\n",
    "1. Rescale video to fill vertical screen.\n",
    "2. Crop image to center (Center Crop).\n",
    "3. Apply OPERATORS' FORGE watermark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e73823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Formatting output/short_1.mp4 to 9:16...\n",
      "✅ SHORTS PRODUCED: output/short_1_branded.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.VideoClip import TextClip, ColorClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "\n",
    "def format_to_shorts(input_path: str, output_path: str):\n",
    "    \"\"\"Processes horizontal video to vertical 9:16 format with branding.\"\"\"\n",
    "    print(f\"LOG: Formatting {input_path} to 9:16...\")\n",
    "    \n",
    "    with VideoFileClip(input_path) as clip:\n",
    "        # 1. We calculate proportions (target 1080x1920 for 9:16)\n",
    "        target_ratio = 9/16\n",
    "        w, h = clip.size\n",
    "        \n",
    "        # We scale video so height fits vertical, and width is excessive\n",
    "        # Then we do Center Crop\n",
    "        new_h = h\n",
    "        new_w = int(h * target_ratio)\n",
    "        \n",
    "        # MoviePy v2.x: cropped() instead of crop()\n",
    "        final_clip = clip.cropped(\n",
    "            x_center=w/2, \n",
    "            y_center=h/2, \n",
    "            width=new_w, \n",
    "            height=new_h\n",
    "        )\n",
    "\n",
    "        # 2. ADDING BRANDING (Simple status bar at bottom)\n",
    "        # We create simple text overlay\n",
    "        # Note: Requires ImageMagick installed on system for TextClip\n",
    "        try:\n",
    "            brand_overlay = ColorClip(\n",
    "                size=(new_w, 60), \n",
    "                color=(139, 0, 0) # Our Dark Red #8B0000\n",
    "            ).with_duration(final_clip.duration).with_opacity(0.8).with_position((\"center\", \"bottom\"))\n",
    "            \n",
    "            result = CompositeVideoClip([final_clip, brand_overlay])\n",
    "        except:\n",
    "            print(\"LOG: Skipping branding (no ImageMagick). Rendering clean vertical.\")\n",
    "            result = final_clip\n",
    "\n",
    "        # 3. FINAL RENDER\n",
    "        result.write_videofile(\n",
    "            output_path,\n",
    "            codec=\"libx264\",\n",
    "            audio_codec=\"aac\",\n",
    "            logger=None\n",
    "        )\n",
    "        print(f\"✅ SHORTS PRODUCED: {output_path}\")\n",
    "\n",
    "# TEST: We process first cut clip\n",
    "if os.path.exists(\"output/short_1.mp4\"):\n",
    "    format_to_shorts(\"output/short_1.mp4\", \"output/short_1_branded.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92557c1e",
   "metadata": {},
   "source": [
    "## STATUS: STAGE 3 COMPLETED (FACTORY_ACTIVE)\n",
    "\n",
    "The system has gone through the full path from raw file `test_video.mp4` to vertical, branded Short `short_1_branded.mp4`.\n",
    "\n",
    "**Stage 3 Achievements:**\n",
    "- [x] Automatic extraction based on Gemini metadata.\n",
    "- [x] Conversion to vertical format (Vertical Reframing).\n",
    "- [x] Branding layer implementation.\n",
    "\n",
    "**Next stage (M_04): Long-term Memory (Qdrant).**\n",
    "We will save our analyses and cut clips to vector database, so the system learns your style and knows what it published in the past."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omni-operator-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
