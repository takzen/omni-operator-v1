{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c7cccf",
   "metadata": {},
   "source": [
    "# [M_01] PROTOCOL: MULTIMODAL ANALYSIS (GEMINI 3 FLASH)\n",
    "\n",
    "**PROJECT:** OMNI-OPERATOR-V1  \n",
    "**ORGANIZATION:** [OPERATORS' FORGE](https://takzenai-hub.pl)  \n",
    "**STATUS:** VISION_OPERATION\n",
    "\n",
    "This module implements the logic for multimodal analysis of raw video material. We use the **Gemini 3 Flash** model to directly extract key moments (hooks) and narrative structure.\n",
    "\n",
    "**Why is this groundbreaking?**\n",
    "1. **No transcription:** We don't waste time on Whisper/STT. Gemini sees gestures, emotions, and on-screen text.\n",
    "2. **Video Grounding:** The model connects audio with specific video frames.\n",
    "3. **Structured Outputs:** The result goes directly to the Pydantic model, ready for automatic editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc01b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Analytics system ready. ROOT directory: c:\\Users\\takze\\OneDrive\\Pulpit\\project\\omni-operator-v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from google import genai  \n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from src.core.config import settings\n",
    "\n",
    "# 1. WORKING DIRECTORY CORRECTION\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# Adding src to path to make the core module visible\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "\n",
    "\n",
    "# 2. ENGINE CONFIGURATION\n",
    "client = genai.Client(api_key=settings.gemini_api_key)  \n",
    "\n",
    "print(f\"LOG: Analytics system ready. ROOT directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8aeba",
   "metadata": {},
   "source": [
    "## 1. Data Contract Definition (Structured Output)\n",
    "\n",
    "Establishing a strict schema is crucial for Stage 3 (FFmpeg Editing). Gemini must return data in a format that Python will understand flawlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5bdec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Pydantic data models initialized.\n"
     ]
    }
   ],
   "source": [
    "class ShotCandidate(BaseModel):\n",
    "    \"\"\"Represents a video fragment selected for viral potential.\"\"\"\n",
    "    start: str = Field(description=\"Fragment start timestamp (MM:SS format)\")\n",
    "    end: str = Field(description=\"Fragment end timestamp (MM:SS format)\")\n",
    "    visual_description: str = Field(description=\"Description of what's happening on screen at this moment\")\n",
    "    narrative_hook: str = Field(description=\"Why this moment will capture viewer's attention\")\n",
    "    score: int = Field(description=\"Viral potential on a scale of 1-10\")\n",
    "\n",
    "class VideoAnalysisReport(BaseModel):\n",
    "    \"\"\"Complete report from source material analysis.\"\"\"\n",
    "    main_topic: str = Field(description=\"Main topic and purpose of the recording\")\n",
    "    suggested_titles: List[str] = Field(description=\"Catchy title suggestions (max 3)\")\n",
    "    clips: List[ShotCandidate] = Field(description=\"List of suggested fragments to extract\")\n",
    "\n",
    "print(\"LOG: Pydantic data models initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ea6e6",
   "metadata": {},
   "source": [
    "## 2. Media File Management (Google File API)\n",
    "\n",
    "Before analysis, the video file must be indexed by Google. Gemini 3 Flash requires the file to have `ACTIVE` status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1defd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gemini(file_path: str):\n",
    "    \"\"\"Uploads file to API and monitors processing status.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Error: File {file_path} not found in ROOT directory.\")\n",
    "\n",
    "    print(f\"LOG: Uploading material {file_path} to Google Cloud...\")\n",
    "    \n",
    "    # NEW SDK: client.files.upload\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        media_file = client.files.upload(file=f, config={\"mime_type\": \"video/mp4\"})\n",
    "    \n",
    "    # Waiting for processing by Google servers\n",
    "    while media_file.state.name == \"PROCESSING\":\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(3)\n",
    "        # NEW SDK: client.files.get\n",
    "        media_file = client.files.get(name=media_file.name)\n",
    "        \n",
    "    if media_file.state.name == \"FAILED\":\n",
    "        raise RuntimeError(\"LOG: Video processing by Google API failed.\")\n",
    "        \n",
    "    print(f\"\\nLOG: Material active. URI: {media_file.uri}\")\n",
    "    return media_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae0d18",
   "metadata": {},
   "source": [
    "## 3. Executing Analysis (Native Vision & Reasoning)\n",
    "\n",
    "We launch the analysis process. We use the `response_schema` mechanism to force the Gemini 3 Flash model to strictly adhere to our data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f0e1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Uploading material test_video.mp4 to Google Cloud...\n",
      "......\n",
      "LOG: Material active. URI: https://generativelanguage.googleapis.com/v1beta/files/8tq1dytjkitn\n",
      "LOG: Agent is analyzing image and audio...\n",
      "\n",
      "=============================================\n",
      "üöÄ REPORT: A COLLECTION OF HIGH-STAKES SCIENCE FICTION ACTION AND DRAMATIC SCENES FEATURING ADVANCED ROBOTICS, FUTURISTIC WARFARE, AND EMOTIONAL CHARACTER CONFRONTATIONS.\n",
      "=============================================\n",
      "CLIP 1: [00:05 - 00:25] (Score: 9/10)\n",
      "VISUAL: A dramatic close-up of a woman with bionic eye implants confronting a man as futuristic HUDs glitch in the background while a giant machine looms.\n",
      "HOOK: Emotional betrayal meets futuristic technology in this high-tension confrontation that immediately draws the viewer into a complex sci-fi world.\n",
      "\n",
      "CLIP 2: [01:30 - 02:00] (Score: 10/10)\n",
      "VISUAL: Giant mechanical walkers invade a grand, overgrown cathedral-like building while a soldier engages in a desperate shootout while swinging from a rope.\n",
      "HOOK: Witness an epic, high-octane battle between human resistance and massive mechanical invaders in a stunning display of CGI action.\n",
      "\n",
      "CLIP 3: [02:10 - 02:40] (Score: 8/10)\n",
      "VISUAL: A technical expert frantically attempts to complete a memory overwrite while the giant robot stands deactivated in a rainy city setting.\n",
      "HOOK: The final countdown to resolve the conflict depends on a high-stakes technical hack, blending suspense with futuristic themes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL: Make sure the test_video.mp4 file is in your root folder!\n",
    "INPUT_FILE = \"test_video.mp4\"\n",
    "\n",
    "async def run_multimodal_analysis():\n",
    "    try:\n",
    "        # 1. Media upload\n",
    "        video_handle = upload_to_gemini(INPUT_FILE)\n",
    "        \n",
    "        # 2. Model definition (NEW SDK - provide as string)\n",
    "        model_id = \"gemini-3-flash-preview\" \n",
    "        \n",
    "        prompt = (\n",
    "            \"Analyze this video recording for creating short content (Shorts/TikTok). \"\n",
    "            \"Identify the main topic and select the 3 best moments. \"\n",
    "            \"IMPORTANT: Each clip must last between 15 and 60 seconds. \"\n",
    "            \"Return the result as clean JSON compliant with the VideoAnalysisReport structure.\"\n",
    "        )\n",
    "        \n",
    "        # 3. Analysis with schema enforcement (NEW SDK)\n",
    "        print(\"LOG: Agent is analyzing image and audio...\")\n",
    "        response = client.models.generate_content(\n",
    "            model=model_id,\n",
    "            contents=[video_handle, prompt],\n",
    "            config={\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_schema\": VideoAnalysisReport\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 4. Parsing and validation\n",
    "        # NEW SDK: try using response.parsed or fallback to text\n",
    "        if hasattr(response, 'parsed') and response.parsed:\n",
    "            report = response.parsed\n",
    "        else:\n",
    "            report_data = json.loads(response.text)\n",
    "            report = VideoAnalysisReport.model_validate(report_data)\n",
    "        \n",
    "        # 5. Results presentation\n",
    "        print(\"\\n\" + \"=\"*45)\n",
    "        print(f\"üöÄ REPORT: {report.main_topic.upper()}\")\n",
    "        print(\"=\"*45)\n",
    "        for i, clip in enumerate(report.clips, 1):\n",
    "            print(f\"CLIP {i}: [{clip.start} - {clip.end}] (Score: {clip.score}/10)\")\n",
    "            print(f\"VISUAL: {clip.visual_description}\")\n",
    "            print(f\"HOOK: {clip.narrative_hook}\\n\")\n",
    "            \n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå OPERATIONAL ERROR: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# EXECUTION\n",
    "analysis_result = await run_multimodal_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963544d",
   "metadata": {},
   "source": [
    "## STATUS: MODULE 01 COMPLETED\n",
    "\n",
    "We have ready input data for editing. The system \"understood\" the video and identified moments to extract.\n",
    "\n",
    "**Next steps:**\n",
    "1. Save the notebook.\n",
    "2. Go to `notebooks/02_AGENT_COPYWRITER.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omni-operator-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
